# WACV-2024-Papers
![Alt text](96748913c73db498eb8249e43c245b8.jpg)
## ä¼šè®®æ—¶é—´ï¼š2024å¹´1æœˆ3-7æ—¥
## ä¼šè®®ç½‘å€ï¼šhttps://wacv2024.thecvf.com/

## ğŸ“¢ğŸ“¢ğŸ“¢è·å¥–è®ºæ–‡

#### ğŸ†æœ€ä½³è®ºæ–‡å¥–(Algorithms)
[Conditional Velocity Score Estimation for Image Restoration](https://openaccess.thecvf.com/content/WACV2024/papers/Shi_Conditional_Velocity_Score_Estimation_for_Image_Restoration_WACV_2024_paper.pdf)

#### ğŸ†æœ€ä½³è®ºæ–‡å¥–(Applications)
[WildlifeDatasets: An Open-Source Toolkit for Animal Re-Identification](https://openaccess.thecvf.com/content/WACV2024/papers/Cermak_WildlifeDatasets_An_Open-Source_Toolkit_for_Animal_Re-Identification_WACV_2024_paper.pdf)

#### ğŸ†æœ€ä½³å­¦ç”Ÿè®ºæ–‡
[Wino Vidi Vici: Conquering Numerical Instability of 8-Bit Winograd Convolution for Accurate Inference Acceleration on Edge](https://openaccess.thecvf.com/content/WACV2024/papers/Mori_Wino_Vidi_Vici_Conquering_Numerical_Instability_of_8-Bit_Winograd_Convolution_WACV_2024_paper.pdf)

#### ğŸ†æœ€ä½³è®ºæ–‡è£èª‰æå
[ParticleNeRF: A Particle-Based Encoding for Online Neural Radiance Fields](https://openaccess.thecvf.com/content/WACV2024/papers/Abou-Chakra_ParticleNeRF_A_Particle-Based_Encoding_for_Online_Neural_Radiance_Fields_WACV_2024_paper.pdf)

## æŸ¥çœ‹2023å¹´ç»¼è¿°æ–‡çŒ®ç‚¹è¿™é‡Œâ†˜ï¸[2023-CV-Surveys](https://github.com/52CV/CV-Surveys)

## 2024 å¹´è®ºæ–‡åˆ†ç±»æ±‡æ€»æˆ³è¿™é‡Œ
â†˜ï¸[WACV-2024-Papers](https://github.com/52CV/WACV-2024-Papers)

## 2023 å¹´è®ºæ–‡åˆ†ç±»æ±‡æ€»æˆ³è¿™é‡Œ
â†˜ï¸[CVPR-2023-Papers](https://github.com/52CV/CVPR-2023-Papers)
â†˜ï¸[WACV-2023-Papers](https://github.com/52CV/WACV-2023-Papers)
â†˜ï¸[ICCV-2023-Papers](https://github.com/52CV/ICCV-2023-Papers)

## [2022 å¹´è®ºæ–‡åˆ†ç±»æ±‡æ€»æˆ³è¿™é‡Œ](#000)
## [2021 å¹´è®ºæ–‡åˆ†ç±»æ±‡æ€»æˆ³è¿™é‡Œ](#00)
## [2020 å¹´è®ºæ–‡åˆ†ç±»æ±‡æ€»æˆ³è¿™é‡Œ](#0)


## ç›®å½•

|:cat:|:dog:|:tiger:|:wolf:|
|------|------|------|------|
|[1.å…¶å®ƒ(Other)](#1)|[2.SR(è¶…åˆ†è¾¨ç‡)](#2)|[3.Image/Video Retrieval(å›¾åƒ/è§†é¢‘æ£€ç´¢)](#3)|[4.Image/Video Caption(å›¾åƒ/è§†é¢‘å­—å¹•)](#4)|
|[5.Image/Video Composition(å›¾åƒ/è§†é¢‘å‹ç¼©)](#5)|[6.Medical Image(åŒ»å­¦å›¾åƒå¤„ç†)](#6)|[7.3D(ä¸‰ç»´é‡å»º\ä¸‰ç»´è§†è§‰)](#7)|[8.Face(äººè„¸æŠ€æœ¯)](#8)|
|[9.Image Segmentation(å›¾åƒåˆ†å‰²)](#9)|[10.Object Detector(ç›®æ ‡æ£€æµ‹)](#10)|[11.Object Tracking(ç›®æ ‡è·Ÿè¸ª)](#11)|[12.UAV/RS/Satellite Image(æ— äººæœº/é¥æ„Ÿ/å«æ˜Ÿå›¾åƒ)](#12)|
|[13.Reid(äººå‘˜é‡è¯†åˆ«/æ­¥æ€è¯†åˆ«/è¡Œäººæ£€æµ‹)](#13)|[14.OCR(æ–‡æœ¬æ£€æµ‹è¯†åˆ«)](#14)|[15.Video](#15)|[16.Action Detection(åŠ¨ä½œæ£€æµ‹)](#16)|
|[17.Human Pose Estimation(äººä½“å§¿æ€ä¼°è®¡)](#17)|[18.GAN/ç”Ÿæˆ](#18)|[19.SLAM/AR/VR/Robotics(å¢å¼º/è™šæ‹Ÿç°å®/æœºå™¨äºº)](#19)|[20.VQA(è§†è§‰é—®ç­”)](#20)|


## Computed Imaging(è®¡ç®—æˆåƒï¼Œå¦‚å…‰å­¦ã€å‡ ä½•ã€å…‰åœºæˆåƒç­‰)
* [On the Quantification of Image Reconstruction Uncertainty without Training Data](http://arxiv.org/abs/2311.09639v1)

## Neural Radiance Fields(NeRF)
* [Hyb-NeRF: A Multiresolution Hybrid Encoding for Neural Radiance Fields](https://arxiv.org/abs/2311.12490)
* [Fast Sun-aligned Outdoor Scene Relighting based on TensoRF](http://arxiv.org/abs/2311.03965v1)
* [ParticleNeRF: A Particle-Based Encoding for Online Neural Radiance Fields](https://openaccess.thecvf.com/content/WACV2024/papers/Abou-Chakra_ParticleNeRF_A_Particle-Based_Encoding_for_Online_Neural_Radiance_Fields_WACV_2024_paper.pdf)

## Deepfake
* [Weakly-supervised deepfake localization in diffusion-generated images](http://arxiv.org/abs/2311.04584v1)

## Biometrics(ç”Ÿç‰©ç‰¹å¾è¯†åˆ«)
* [Fingervein Verification using Convolutional Multi-Head Attention Network](http://arxiv.org/abs/2310.16808v1)
* [FarSight: A Physics-Driven Whole-Body Biometric System at Large Distance and Altitude](http://arxiv.org/abs/2306.17206)

##
* [NITEC: Versatile Hand-Annotated Eye Contact Dataset for Ego-Vision Interaction](http://arxiv.org/abs/2311.04505v1)<br>:star:[code](https://github.com/thohemp/nitec)

## Style Transfer(é£æ ¼è¿ç§»)
* [Multimodality-guided Image Style Transfer using Cross-modal GAN Inversion](http://arxiv.org/abs/2312.01671v1)<br>:star:[code](https://hywang66.github.io/mmist/)

## sound(è¯­éŸ³)
* å£°æºå®šä½
  * [Can CLIP Help Sound Source Localization?](http://arxiv.org/abs/2311.04066v1)
* éŸ³é¢‘åˆ†ç¦»  
  * [LAVSS: Location-Guided Audio-Visual Spatial Audio Separation](https://arxiv.org/abs/2310.20446)

## Dataset(æ•°æ®é›†)
* [SyntheWorld: A Large-Scale Synthetic Dataset for Land Cover Mapping and Building Change Detection](https://arxiv.org/abs/2309.01907)<br>:sunflower:[dataset](https://github.com/JTRNEO/SyntheWorld)
* [IndustReal: A Dataset for Procedure Step Recognition Handling Execution Errors in Egocentric Videos in an Industrial-Like Setting](http://arxiv.org/abs/2310.17323v1)<br>:star:[code](https://github.com/TimSchoonbeek/IndustReal)
* [SICKLE: A Multi-Sensor Satellite Imagery Dataset Annotated with Multiple Key Cropping Parameters](https://arxiv.org/abs/2312.00069)
* [SeaTurtleID2022: A Long-Span Dataset for Reliable Sea Turtle Re-Identification](https://openaccess.thecvf.com/content/WACV2024/papers/Adam_SeaTurtleID2022_A_Long-Span_Dataset_for_Reliable_Sea_Turtle_Re-Identification_WACV_2024_paper.pdf)
* [Amodal Intra-Class Instance Segmentation: Synthetic Datasets and Benchmark](http://arxiv.org/abs/2303.06596)
* åŸºå‡†
  * [ISAR: A Benchmark for Single- and Few-Shot Object Instance Segmentation and Re-Identification](http://arxiv.org/abs/2311.02734v1)
  * [ConeQuest: A Benchmark for Cone Segmentation on Mars](http://arxiv.org/abs/2311.08657v1)<br>:star:[code](https://github.com/kerner-lab/ConeQuest)


## Vision Transformers
* [Open-NeRF: Towards Open Vocabulary NeRF Decomposition](http://arxiv.org/abs/2310.16383v1)
* [Limited Data, Unlimited Potential: A Study on ViTs Augmented by Masked Autoencoders](https://arxiv.org/abs/2310.20704)
* [GTP-ViT: Efficient Vision Transformers via Graph-based Token Propagation](http://arxiv.org/abs/2311.03035v1)<br>:star:[code](https://github.com/Ackesnal/GTP-ViT)
* [SBCFormer: Lightweight Network Capable of Full-size ImageNet Classification at 1 FPS on Single Board Computers](http://arxiv.org/abs/2311.03747v1)<br>:star:[code](https://github.com/xyongLu/SBCFormer)

## Edge Detection(è¾¹ç¼˜æ£€æµ‹)
* [Self-Supervised Edge Detection Reconstruction for Topology-Informed 3D Axon Segmentation and Centerline Detection](https://openaccess.thecvf.com/content/WACV2024/papers/Xu_Self-Supervised_Edge_Detection_Reconstruction_for_Topology-Informed_3D_Axon_Segmentation_and_WACV_2024_paper.pdf)

## Dense Prediction(å¯†é›†é¢„æµ‹)
* [PolyMaX: General Dense Prediction with Mask Transformer](http://arxiv.org/abs/2311.05770v1)

## Visual Tampering Detection(è§†è§‰ç¯¡æ”¹æ£€æµ‹)
* åŒ…è£¹é˜²ä¼ªæ£€æµ‹
  * [TAMPAR: Visual Tampering Detection for Parcel Logistics in Postal Supply Chains](http://arxiv.org/abs/2311.03124v1)<br>:star:[code](https://a-nau.github.io/tampar)

## visual industrial inspection(å·¥ä¸šæ£€æµ‹)
* [Attention Modules Improve Image-Level Anomaly Detection for Industrial Inspection: A DifferNet Case Study](http://arxiv.org/abs/2311.02747v1)


## Anomaly Detection
* [Cheating Depth: Enhancing 3D Surface Anomaly Detection via Depth Simulation](http://arxiv.org/abs/2311.01117v1)


## Image Fusion(å›¾åƒèåˆ)
* [Bridging the Gap between Multi-focus and Multi-modal: A Focused Integration Framework for Multi-modal Image Fusion](http://arxiv.org/abs/2311.01886v1)<br>:star:[code](https://github.com/ixilai/MFIF-MMIF)

## Image Classification(å›¾åƒåˆ†ç±»)
* å°æ ·æœ¬åˆ†ç±»
  * [Domain Aligned CLIP for Few-shot Classification](http://arxiv.org/abs/2311.09191v1)

## Image Progress(ä½å±‚å›¾åƒå¤„ç†ã€è´¨é‡è¯„ä»·)
* å›¾åƒæ¢å¤
  * [Conditional Velocity Score Estimation for Image Restoration](https://openaccess.thecvf.com/content/WACV2024/papers/Shi_Conditional_Velocity_Score_Estimation_for_Image_Restoration_WACV_2024_paper.pdf)
* å›¾åƒçŸ«æ­£
  * [4K-Resolution Photo Exposure Correction at 125 FPS with ~8K Parameters](http://arxiv.org/abs/2311.08759v1)<br>:star:[code](https://github.com/Zhou-Yijie/MSLTNet)
* å›¾åƒè´¨é‡è¯„ä¼°
  * [Learning Generalizable Perceptual Representations for Data-Efficient No-Reference Image Quality Assessment](https://arxiv.org/abs/2312.04838)

## Semi-supervised learning
* æ— ç›‘ç£å­¦ä¹ 
  * [United We Stand, Divided We Fall: UnityGraph for Unsupervised Procedure Learning from Videos](http://arxiv.org/abs/2311.03550v1)
* åŠç›‘ç£å­¦ä¹ 
  * [SequenceMatch: Revisiting the design of weak-strong augmentations for Semi-supervised learning](https://arxiv.org/abs/2310.15787)<br>:star:[code](https://github.com/beandkay/SequenceMatch)
  * [Debiasing, calibrating, and improving Semi-supervised Learning performance via simple Ensemble Projector](https://arxiv.org/abs/2310.15764)<br>:star:[code](https://github.com/beandkay/EPASS)
  * [Improving Open-Set Semi-Supervised Learning With Self-Supervision](http://arxiv.org/abs/2301.10127)
* è‡ªç›‘ç£å­¦ä¹ 
  * [CycleCL: Self-supervised Learning for Periodic Videos](http://arxiv.org/abs/2311.03402v1)
  * [Self-Supervised Learning for Visual Relationship Detection through Masked Bounding Box Reconstruction](http://arxiv.org/abs/2311.04834v1)<br>:star:[code](https://github.com/deeplab-ai/SelfSupervisedVRD)

## Few/Zero-Shot Learning/Domain Generalization/Adaptation(å°/é›¶æ ·æœ¬/åŸŸæ³›åŒ–/åŸŸé€‚åº”)
* é›¶æ ·æœ¬å­¦ä¹ 
  * [GIPCOL: Graph-Injected Soft Prompting for Compositional Zero-Shot Learning](http://arxiv.org/abs/2311.05729v1)
  * [Meta-Learned Attribute Self-Interaction Network for Continual and Generalized Zero-Shot Learning](http://arxiv.org/abs/2312.01167v1)
* å°æ ·æœ¬å­¦ä¹ 
  * [Hyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin](https://arxiv.org/abs/2309.10013)
* DG
  * [Learning Class and Domain Augmentations for Single-Source Open-Domain Generalization](http://arxiv.org/abs/2311.02599v1)
* DA
  * [Gradual Source Domain Expansion for Unsupervised Domain Adaptation](http://arxiv.org/abs/2311.09599v1)
  * [Bridging Generalization Gaps in High Content Imaging Through Online Self-Supervised Domain Adaptation](https://arxiv.org/abs/2311.12623)<br>:star:[code](https://github.com/cfredinh/coda)
  * [GLAD: Global-Local View Alignment and Background Debiasing for Unsupervised Video Domain Adaptation with Large Domain Gap](https://arxiv.org/abs/2311.12467)<br>:star:[code](https://github.com/KHU-VLL/GLAD)
  * [Aligning Non-Causal Factors for Transformer-Based Source-Free Domain Adaptation](https://arxiv.org/abs/2311.16294)<br>:house:[project](https://val.cds.iisc.ac.in/C-SFTrans/)
  * [Robust Unsupervised Domain Adaptation Through Negative-View Regularization](https://openaccess.thecvf.com/content/WACV2024/papers/Jang_Robust_Unsupervised_Domain_Adaptation_Through_Negative-View_Regularization_WACV_2024_paper.pdf)

## Machine Learning(æœºå™¨å­¦ä¹ )
* æŒç»­å­¦ä¹ /å¢é‡å­¦ä¹ 
  * [Efficient Expansion and Gradient Based Task Inference for Replay Free Incremental Learning](http://arxiv.org/abs/2312.01188v1)
  * ç±»å¢é‡
    * [Wakening Past Concepts without Past Data: Class-Incremental Learning from Online Placebos](http://arxiv.org/abs/2310.16115v1)<br>:star:[code](https://github.com/yaoyao-liu/online-placebos)
    * [Robust Feature Learning and Global Variance-Driven Classifier Alignment for Long-Tail Class Incremental Learning](http://arxiv.org/abs/2311.01227v1)
  * CL
    * [Plasticity-Optimized Complementary Networks for Unsupervised Continual Learning](https://arxiv.org/abs/2309.06086)
* åº¦é‡å­¦ä¹ 
  * [ProcSim: Proxy-based Confidence for Robust Similarity Learning](http://arxiv.org/abs/2311.00668v1)
* å¯¹æŠ—å­¦ä¹ 
  * [Army of Thieves: Enhancing Black-Box Model Extraction via Ensemble based sample selection](http://arxiv.org/abs/2311.04588v1)
* ä¸»åŠ¨å­¦ä¹ 
  * [Training Ensembles With Inliers and Outliers for Semi-Supervised Active Learning](https://openaccess.thecvf.com/content/WACV2024/papers/Stojnic_Training_Ensembles_With_Inliers_and_Outliers_for_Semi-Supervised_Active_Learning_WACV_2024_paper.pdf)
* è”é‚¦å­¦ä¹ 
  * [MetaVers: Meta-Learned Versatile Representations for Personalized Federated Learning](https://openaccess.thecvf.com/content/WACV2024/papers/Lim_MetaVers_Meta-Learned_Versatile_Representations_for_Personalized_Federated_Learning_WACV_2024_paper.pdf)
* å¯¹æ¯”å­¦ä¹ 
  * [Activity-Based Early Autism Diagnosis Using a Multi-Dataset Supervised Contrastive Learning Approach](https://openaccess.thecvf.com/content/WACV2024/papers/Rani_Activity-Based_Early_Autism_Diagnosis_Using_a_Multi-Dataset_Supervised_Contrastive_Learning_WACV_2024_paper.pdf)

## Model Compression/Knowledge Distillation/Pruning(æ¨¡å‹å‹ç¼©/çŸ¥è¯†è’¸é¦/å‰ªæ)
* [Wino Vidi Vici: Conquering Numerical Instability of 8-Bit Winograd Convolution for Accurate Inference Acceleration on Edge](https://openaccess.thecvf.com/content/WACV2024/papers/Mori_Wino_Vidi_Vici_Conquering_Numerical_Instability_of_8-Bit_Winograd_Convolution_WACV_2024_paper.pdf)
* é‡åŒ–
  * [Reducing the Side-Effects of Oscillations in Training of Quantized YOLO Networks](http://arxiv.org/abs/2311.05109v1)
  * [Evidential Uncertainty Quantification: A Variance-Based Perspective](https://arxiv.org/abs/2311.11367)
* å‰ªæ
  * [Token Fusion: Bridging the Gap between Token Pruning and Token Merging](http://arxiv.org/abs/2312.01026v1)

## NAS
* [FLORA: Fine-grained Low-Rank Architecture Search for Vision Transformer](http://arxiv.org/abs/2311.03912v1)<br>:star:[code](https://github.com/shadowpa0327/FLORA)

## Optical Flow Estimation(å…‰æµä¼°è®¡)
* [Detection Defenses: An Empty Promise against Adversarial Patch Attacks on Optical Flow](http://arxiv.org/abs/2310.17403v1)<br>:star:[code](https://github.com/cv-stuttgart/DetectionDefenses)
* [CCMR: High Resolution Optical Flow Estimation via Coarse-to-Fine Context-Guided Motion Reasoning](http://arxiv.org/abs/2311.02661v1)<br>:star:[code](https://github.com/cv-stuttgart)

## Multimodal(å¤šæ¨¡æ€)
* [Dynamic Multimodal Information Bottleneck for Multimodality Classification](http://arxiv.org/abs/2311.01066v1)<br>:star:[code](https://github.com/BII-wushuang/DMIB)
* [Enhancing Multimodal Compositional Reasoning of Visual Language Models with Generative Negative Mining](https://arxiv.org/abs/2311.03964)<br>:star:[code](https://github.com/ugorsahin/Generative-Negative-Mining)
* [OmniVec: Learning robust representations with cross modal sharing](http://arxiv.org/abs/2311.05709v1)

## Object Pose Estimation(ç‰©ä½“å§¿æ€ä¼°è®¡)
* 6-DoF
  * [Real-time 6-DoF Pose Estimation by an Event-based Camera using Active LED Markers](http://arxiv.org/abs/2310.16618v1)

## Lage Language Models
## Vision-Language(è§†è§‰è¯­è¨€)
* [Towards Addressing the Misalignment of Object Proposal Evaluation for Vision-Language Tasks via Semantic Grounding](https://arxiv.org/abs/2309.00215)

## Animal
* åŠ¨ç‰©é‡è¯†åˆ«
  * [WildlifeDatasets: An Open-Source Toolkit for Animal Re-Identification](https://openaccess.thecvf.com/content/WACV2024/papers/Cermak_WildlifeDatasets_An_Open-Source_Toolkit_for_Animal_Re-Identification_WACV_2024_paper.pdf)

##
* è½¦é“çº¿æ£€æµ‹
  * [CLRerNet: Improving Confidence of Lane Detection With LaneIoU](http://arxiv.org/abs/2305.08366)

## Point-Cloud(ç‚¹äº‘)
* [Cross-Domain Few-Shot Incremental Learning for Point-Cloud Recognition](https://openaccess.thecvf.com/content/WACV2024/papers/Tan_Cross-Domain_Few-Shot_Incremental_Learning_for_Point-Cloud_Recognition_WACV_2024_paper.pdf)

<a name="20"/>

## 20.Visual Answer Questions(è§†è§‰é—®ç­”)
* è§†è§‰å¯¹è¯
  * [VD-GR: Boosting Visual Dialog with Cascaded Spatial-Temporal Multi-Modal GRaphs](http://arxiv.org/abs/2310.16590v1)

<a name="19"/>

## 19.SLAM/Augmented Reality/Virtual Reality/Robotics(å¢å¼º/è™šæ‹Ÿç°å®/æœºå™¨äºº)
* è™šæ‹Ÿè¯•ç©¿
  * [A Generative Multi-Resolution Pyramid and Normal-Conditioning 3D Cloth Draping](http://arxiv.org/abs/2311.02700v1)
  * [GC-VTON: Predicting Globally Consistent and Occlusion Aware Local Flows with Neighborhood Integrity Preservation for Virtual Try-on](http://arxiv.org/abs/2311.04932v1)
* è™šæ‹ŸåŒ–èº«
  * [CVTHead: One-shot Controllable Head Avatar with Vertex-feature Transformer](http://arxiv.org/abs/2311.06443v1)

<a name="18"/>

## 18.GAN/ç”Ÿæˆ
* GAN
  * [PlantPlotGAN: A Physics-Informed Generative Adversarial Network for Plant Disease Prediction](https://arxiv.org/abs/2310.18268)
  * [Soft Curriculum for Learning Conditional GANs With Noisy-Labeled and Uncurated Unlabeled Data](http://arxiv.org/abs/2307.08319)
* æ‰©æ•£
  * [Expanding Expressiveness of Diffusion Models with Limited Data via Self-Distillation based Fine-Tuning](http://arxiv.org/abs/2311.01018v1)
* å›¾åƒç”Ÿæˆ
  * [Improving the Effectiveness of Deep Generative Data](http://arxiv.org/abs/2311.03959v1)
* å›¾åƒåˆæˆ
  * [Painterly Image Harmonization via Adversarial Residual Learning](http://arxiv.org/abs/2311.08646v1)

<a name="17"/>

## 17.Human Pose Estimation
* [Active Transfer Learning for Efficient Video-Specific Human Pose Estimation](http://arxiv.org/abs/2311.05041v1)<br>:star:[code](https://github.com/ImIntheMiddle/VATL4Pose-WACV2024)
* æ‰‹éƒ¨
  * æ‰‹è¯­ç¿»è¯‘
    * [Fingerspelling PoseNet: Enhancing Fingerspelling Translation with Pose-Based Transformer Models](https://arxiv.org/abs/2311.12128)<br>:star:[code](https://github.com/pooyafayyaz/Fingerspelling-PoseNet)
  * æ‰‹éƒ¨å§¿æ€ä¼°è®¡
    * [HMP: Hand Motion Priors for Pose and Shape Estimation From Video](https://openaccess.thecvf.com/content/WACV2024/papers/Duran_HMP_Hand_Motion_Priors_for_Pose_and_Shape_Estimation_From_WACV_2024_paper.pdf)

<a name="16"/>

## 16.Action Detection(åŠ¨ä½œæ£€æµ‹)
* å°æ ·æœ¬åŠ¨ä½œæ£€æµ‹
  * [Semantic-aware Video Representation for Few-shot Action Recognition](http://arxiv.org/abs/2311.06218v1)
* æ—¶åºåŠ¨ä½œåˆ†å‰²
  * [OTAS: Unsupervised Boundary Detection for Object-Centric Temporal Action Segmentation](https://arxiv.org/abs/2309.06276)
* åŠ¨ä½œæ£€æµ‹
  * [A Hybrid Graph Network for Complex Activity Detection in Video](http://arxiv.org/abs/2310.17493v1)
* åŠ¨ä½œé¢„æµ‹
  * [Object-centric Video Representation for Long-term Action Anticipation](http://arxiv.org/abs/2311.00180v1)<br>:star:[code](https://github.com/brown-palm/ObjectPrompt)
* åŠ¨ä½œè´¨é‡è¯„ä¼°
  * [PECoP: Parameter Efficient Continual Pretraining for Action Quality Assessment](http://arxiv.org/abs/2311.07603v1)<br>:star:[code](https://github.com/Plrbear/PECoP)

<a name="15"/>

## 15.Video
* è§†é¢‘åˆ†å‰²
  * [Correlation-aware active learning for surgery video segmentation](http://arxiv.org/abs/2311.08811v1)
* è§†é¢‘è¯†åˆ«
  * [Automated Sperm Assessment Framework and Neural Network Specialized for Sperm Video Recognition](http://arxiv.org/abs/2311.05927v1)
* è§†é¢‘æ—¶åˆ»æ£€ç´¢
  * [Zero-Shot Video Moment Retrieval from Frozen Vision-Language Models](https://arxiv.org/abs/2309.00661)
* VAD
  * [A Coarse-to-Fine Pseudo-Labeling (C2FPL) Framework for Unsupervised Video Anomaly Detection](http://arxiv.org/abs/2310.17650v1)

<a name="14"/>

## 14.OCR(æ–‡æœ¬æ£€æµ‹è¯†åˆ«)
* [DTrOCR: Decoder-only Transformer for Optical Character Recognition](https://arxiv.org/abs/2308.15996)
* [On Manipulating Scene Text in the Wild with Diffusion Models](http://arxiv.org/abs/2311.00734v1)
* [DECDM: Document Enhancement using Cycle-Consistent Diffusion Models](http://arxiv.org/abs/2311.09625v1)
* Text Spotting
  * [Harnessing the Power of Multi-Lingual Datasets for Pre-training: Towards Enhancing Text Spotting Performance](https://arxiv.org/abs/2310.00917)
  * [Hierarchical Text Spotter for Joint Text Spotting and Layout Analysis](https://arxiv.org/abs/2310.17674)

<a name="13"/>

## 13.Reid(äººå‘˜é‡è¯†åˆ«/æ­¥æ€è¯†åˆ«/è¡Œäººæ£€æµ‹)
* Reid
  * [HashReID: Dynamic Network with Binary Codes for Efficient Person Re-identification](https://arxiv.org/abs/2308.11900)
  * [Mitigate Domain Shift by Primary-Auxiliary Objectives Association for Generalizing Person ReID](https://arxiv.org/abs/2310.15913)
* è¡Œäººè¯†åˆ«
  * [ShARc: Shape and Appearance Recognition for Person Identification In-the-wild](https://arxiv.org/abs/2310.15946)
* è¡Œäººæœç´¢
  * [DDAM-PS: Diligent Domain Adaptive Mixer for Person Search](https://arxiv.org/abs/2310.20706)<br>:star:[code](https://github.com/mustansarfiaz/DDAM-PS)
* äººç¾¤è®¡æ•°
  * åŸºäºçº¢å¤–çš„äººç¾¤è®¡æ•°
    * [Evaluating Supervision Levels Trade-Offs for Infrared-Based People Counting](https://arxiv.org/abs/2311.11974)<br>:star:[code](https://github.com/tortueTortue/IRPeopleCounting)
* æ­¥æ€è¯†åˆ«
  * [You Can Run but not Hide: Improving Gait Recognition with Intrinsic Occlusion Type Awareness](http://arxiv.org/abs/2312.02290v1)

<a name="12"/>

## 12.UAV/Remote Sensing/Satellite Image(æ— äººæœº/é¥æ„Ÿ/å«æ˜Ÿå›¾åƒ)
* æ ‘å† æ£€æµ‹
  * [ShadowSense: Unsupervised Domain Adaptation and Feature Fusion for Shadow-Agnostic Tree Crown Detection from RGB-Thermal Drone Imagery](http://arxiv.org/abs/2310.16212v1)<br>:star:[code](https://github.com/rudrakshkapil/ShadowSense)<br>:star:[code](https://github.com/rudrakshkapil/ShadowSense)
* å˜åŒ–æ£€æµ‹
  * [Effective Restoration of Source Knowledge in Continual Test Time Adaptation](http://arxiv.org/abs/2311.04991v1)
  * [SeaDSC: A video-based unsupervised method for dynamic scene change detection in unmanned surface vehicles](https://arxiv.org/abs/2311.11580)

<a name="11"/>

## 11.Object Tracking(ç›®æ ‡è·Ÿè¸ª)
* [Separable Self and Mixed Attention Transformers for Efficient Object Tracking](https://arxiv.org/abs/2309.03979)<br>:star:[code](https://github.com/goutamyg/SMAT)
* [Tracking Skiers from the Top to the Bottom](https://arxiv.org/abs/2312.09723)<br>:star:[code](https://machinelearning.uniud.it/datasets/skitb)
* MOT
  * [Contrastive Learning for Multi-Object Tracking with Transformers](http://arxiv.org/abs/2311.08043v1)

<a name="10"/>

## 10.Object Detector(ç›®æ ‡æ£€æµ‹)
* [MultIOD: Rehearsal-free Multihead Incremental Object Detector](https://arxiv.org/abs/2309.05334)
* [Towards Few-Annotation Learning for Object Detection: Are Transformer-based Models More Efficient ?](https://arxiv.org/abs/2310.19936)
* [TPSeNCE: Towards Artifact-Free Realistic Rain Generation for Deraining and Object Detection in Rain](http://arxiv.org/abs/2311.00660v1)<br>:star:[code](https://github.com/ShenZheng2000/TPSeNCE)
* [Beyond Classification: Definition and Density-based Estimation of Calibration in Object Detection](https://arxiv.org/abs/2312.06645)
* [Time To Shine: Fine-Tuning Object Detection Models With Synthetic Adverse Weather Images](https://openaccess.thecvf.com/content/WACV2024/papers/Rothmeier_Time_To_Shine_Fine-Tuning_Object_Detection_Models_With_Synthetic_Adverse_WACV_2024_paper.pdf)
* ååŒæ˜¾è‘—ç›®æ ‡æ£€æµ‹
  * [Unsupervised and semi-supervised co-salient object detection via segmentation frequency statistics](http://arxiv.org/abs/2311.06654v1)
* å¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹
  * [LP-OVOD: Open-Vocabulary Object Detection by Linear Probing](http://arxiv.org/abs/2310.17109v1)<br>:star:[code](https://github.com/VinAIResearch/LP-OVOD)
* æ˜¾è‘—ç›®æ ‡æ£€æµ‹
  * [3SD: Self-Supervised Saliency Detection With No Labels](http://arxiv.org/abs/2203.04478)
* å°ç›®æ ‡æ£€æµ‹
  * [RPCANet: Deep Unfolding RPCA Based Infrared Small Target Detection](http://arxiv.org/abs/2311.00917v1)
  * [S$^3$AD: Semi-supervised Small Apple Detection in Orchard Environments](http://arxiv.org/abs/2311.05029v1)<br>:house:[project](http://www.inf.uni-hamburg.de/mad)

<a name="9"/>

## 9.Image Segmentation(å›¾åƒåˆ†å‰²)
* [Robust Source-Free Domain Adaptation for Fundus Image Segmentation](http://arxiv.org/abs/2310.16665v1)<br>:star:[code](https://github.com/LinGrayy/PLPB)
* è¯­ä¹‰åˆ†å‰²
  * [Unsupervised Domain Adaptation for Semantic Segmentation with Pseudo Label Self-Refinement](http://arxiv.org/abs/2310.16979v1)
  * [Residual Graph Convolutional Network for Bird's-Eye-View Semantic Segmentation](https://arxiv.org/abs/2312.04044)
  * 3Dè¯­ä¹‰åˆ†å‰²  
    * [2D Feature Distillation for Weakly- and Semi-Supervised 3D Semantic Segmentation](https://arxiv.org/abs/2311.15605)
  * å¼€é›†è¯­ä¹‰åˆ†å‰²
    * [FOSSIL: Free Open-Vocabulary Semantic Segmentation Through Synthetic References Retrieval](https://openaccess.thecvf.com/content/WACV2024/papers/Barsellotti_FOSSIL_Free_Open-Vocabulary_Semantic_Segmentation_Through_Synthetic_References_Retrieval_WACV_2024_paper.pdf)
  * ç»†ç²’åº¦è¯­ä¹‰åˆ†å‰²  
    * [CPSeg: Finer-grained Image Semantic Segmentation via Chain-of-Thought Language Prompting](http://arxiv.org/abs/2310.16069v1)
  * å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰² 
    * [Small Objects Matters in Weakly-supervised Semantic Segmentation](https://arxiv.org/abs/2309.14117)
  * åŸŸé€‚åº”è¯­ä¹‰åˆ†å‰²
     * [Generalization by Adaptation: Diffusion-Based Domain Extension for Domain-Generalized Semantic Segmentation](http://arxiv.org/abs/2312.01850v1)<br>:star:[code](https://github.com/JNiemeijer/DIDEX)
* åœºæ™¯ç†è§£
  * [TSP-Transformer: Task-Specific Prompts Boosted Transformer for Holistic Scene Understanding](http://arxiv.org/abs/2311.03427v1)<br>:star:[code](https://github.com/tb2-sy/TSP-Transformer)
  * [Rethink Cross-Modal Fusion in Weakly-Supervised Audio-Visual Video Parsing](http://arxiv.org/abs/2311.08151v1)
* åœºæ™¯åˆ†å‰²
  * [IDD-AW: A Benchmark for Safe and Robust Segmentation of Drive Scenes in Unstructured Traffic and Adverse Weather](https://arxiv.org/abs/2311.14459)
* å°æ ·æœ¬åˆ†å‰²
  * [Pixel Matching Network for Cross-Domain Few-Shot Segmentation](https://openaccess.thecvf.com/content/WACV2024/papers/Chen_Pixel_Matching_Network_for_Cross-Domain_Few-Shot_Segmentation_WACV_2024_paper.pdf)
* è¯­ä¹‰åœºæ™¯åˆ†å‰²
  * [U3DS$^3$: Unsupervised 3D Semantic Scene Segmentation](http://arxiv.org/abs/2311.06018v1)
* VOS
  * [Learning the What and How of Annotation in Video Object Segmentation](http://arxiv.org/abs/2311.04414v1)


<a name="8"/>

## 8.Face(äººè„¸æŠ€æœ¯)
* [ProS: Facial Omni-Representation Learning via Prototype-based Self-Distillation](http://arxiv.org/abs/2311.01929v1)
* [Improving Fairness using Vision-Language Driven Image Augmentation](http://arxiv.org/abs/2311.01573v1)<br>:star:[code](https://github.com/Moreno98/Vision-Language-Bias-Control)
* FPAD
  * [Face Presentation Attack Detection by Excavating Causal Clues and Adapting Embedding Statistics](https://arxiv.org/abs/2308.14551)<br>:star:[code](https://github.com/meilfang/CF-PAD)
* è¯´è¯å¤´
  * [LaughTalk: Expressive 3D Talking Head Generation with Laughter](http://arxiv.org/abs/2311.00994v1)
  * [3D-Aware Talking-Head Video Motion Transfer](http://arxiv.org/abs/2311.02549v1)
  * [THInImg: Cross-modal Steganography for Presenting Talking Heads in Images](https://arxiv.org/abs/2311.17177)
* å¹´é¾„åˆ†ç±»
  * [P-Age: Pexels Dataset for Robust Spatio-Temporal Apparent Age Classification](http://arxiv.org/abs/2311.02432v1)
* äººè„¸è¯†åˆ«
  * [Bias and Diversity in Synthetic-based Face Recognition](http://arxiv.org/abs/2311.03970v1)
  * [Text-Guided Face Recognition using Multi-Granularity Cross-Modal Contrastive Learning](https://arxiv.org/abs/2312.09367)
* äººè„¸é£æ ¼è¿ç§»
  * [3D Face Style Transfer with a Hybrid Solution of NeRF and Mesh Rasterization](https://arxiv.org/abs/2311.13168)

<a name="7"/>

## 7.3D(ä¸‰ç»´é‡å»º\ä¸‰ç»´è§†è§‰)
* æ·±åº¦ä¼°è®¡
  * [Semi-Supervised Semantic Depth Estimation using Symbiotic Transformer and NearFarMix Augmentation](https://arxiv.org/abs/2308.14400)
  * [Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation](http://arxiv.org/abs/2311.01034v1)
  * [Continual Learning of Unsupervised Monocular Depth from Videos](http://arxiv.org/abs/2311.02393v1)
  * [MonoProb: Self-Supervised Monocular Depth Estimation with Interpretable Uncertainty](http://arxiv.org/abs/2311.06137v1)<br>:star:[code](https://github.com/CEA-LIST/MonoProb)
* ä¸‰ç»´é‡å»º
  * [Toward Planet-Wide Traffic Camera Calibration](http://arxiv.org/abs/2311.04243v1)<br>:house:[project](https://www.khiemvuong.com/OpenTrafficCam3D)
  * [Registered and Segmented Deformable Object Reconstruction from a Single View Point Cloud](http://arxiv.org/abs/2311.07357v1)
* æˆ¿é—´å¸ƒå±€
  * [iBARLE: imBalance-Aware Room Layout Estimation](http://arxiv.org/abs/2308.15050)

<a name="6"/>

## 6.Medical Image(åŒ»å­¦å›¾åƒå¤„ç†)
* 3D
  * [Adaptive Latent Diffusion Model for 3D Medical Image to Image Translation: Multi-modal Magnetic Resonance Imaging Study](http://arxiv.org/abs/2311.00265v1)
* æŠ¥å‘Šç”Ÿæˆ
  * [Complex Organ Mask Guided Radiology Report Generation](http://arxiv.org/abs/2311.02329v1)
* åŒ»å­¦å›¾åƒåˆ†å‰²
  * [G-CASCADE: Efficient Cascaded Graph Convolutional Decoding for 2D Medical Image Segmentation](http://arxiv.org/abs/2310.16175v1)
  * [SynergyNet: Bridging the Gap between Discrete and Continuous Representations for Precise Medical Image Segmentation](https://arxiv.org/abs/2310.17764)
  * [MIST: Medical Image Segmentation Transformer with Convolutional Attention Mixing (CAM) Decoder](https://arxiv.org/abs/2310.19898)
* åŒ»å­¦å›¾åƒåˆ†ç±»
  * [PHG-Net: Persistent Homology Guided Medical Image Classification](https://arxiv.org/abs/2311.17243)<br>:star:[code](https://github.com/yaoppeng/TopoClassification)
* ç³–å°¿ç—…è§†ç½‘è†œåˆ†ç±»
  * [Generalizing to Unseen Domains in Diabetic Retinopathy Classification](http://arxiv.org/abs/2310.17255v1)

<a name="5"/>

## 5.Image/Video Composition(å›¾åƒ/è§†é¢‘å‹ç¼©)
* [Differentiable JPEG: The Devil is in the Details](https://arxiv.org/abs/2309.06978)<br>:star:[code](https://github.com/necla-ml/Diff-JPEG)
* IC
  * [Controlling Rate, Distortion, and Realism: Towards a Single Comprehensive Neural Image Compression Model](https://openaccess.thecvf.com/content/WACV2024/papers/Iwai_Controlling_Rate_Distortion_and_Realism_Towards_a_Single_Comprehensive_Neural_WACV_2024_paper.pdf)
* VC
  * [Blurry Video Compression: A Trade-off between Visual Enhancement and Data Compression](http://arxiv.org/abs/2311.04430v1)

<a name="4"/>

## 4.Image/Video Caption(å›¾åƒ/è§†é¢‘å­—å¹•)
* [Augment the Pairs: Semantics-Preserving Image-Caption Pair Augmentation for Grounding-Based Vision and Language Models](http://arxiv.org/abs/2311.02536v1)<br>:star:[code](https://github.com/amzn/augment-the-pairs-wacv2024)

<a name="3"/>

## 3.Image/Video Retrieval(å›¾åƒ/è§†é¢‘æ£€ç´¢)
* å›¾åƒæ£€ç´¢
  * [Bi-Directional Training for Composed Image Retrieval via Text Prompt Learning](http://arxiv.org/abs/2303.16604)
* æ–‡æœ¬-ç©¿æ­æ£€ç´¢(æ—¶å°šæ¨è)
  * [Lost Your Style? Navigating with Semantic-Level Approach for Text-to-Outfit Retrieval](http://arxiv.org/abs/2311.02122v1)

<a name="2"/>

## 2.Super-Resolution(è¶…åˆ†è¾¨ç‡)
* [Scene Text Image Super-resolution based on Text-conditional Diffusion Models](http://arxiv.org/abs/2311.09759v1)
* VSR
  * [Scale-Adaptive Feature Aggregation for Efficient Space-Time Video Super-Resolution](http://arxiv.org/abs/2310.17294v1)

<a name="1"/>

## 1.å…¶å®ƒ
* [REALM: Robust Entropy Adaptive Loss Minimization for Improved Single-Sample Test-Time Adaptation](https://arxiv.org/abs/2309.03964)
* [Occlusion Sensitivity Analysis with Augmentation Subspace Perturbation in Deep Feature Space](https://arxiv.org/abs/2311.15022)
* [SENetV2: Aggregated dense layer for channelwise and global representations](https://arxiv.org/abs/2311.10807)
* [RecycleNet: Latent Feature Recycling Leads to Iterative Decision Refinement](https://arxiv.org/abs/2309.07513)
* [Learning Low-Rank Latent Spaces with Simple Deterministic Autoencoder: Theoretical and Empirical Insights](http://arxiv.org/abs/2310.16194v1)
* [Learning Robust Deep Visual Representations from EEG Brain Recordings](http://arxiv.org/abs/2310.16532v1)
* [MACP: Efficient Model Adaptation for Cooperative Perception](http://arxiv.org/abs/2310.16870v1)<br>:star:[code](https://github.com/PurdueDigitalTwin/MACP)
* [The Background Also Matters: Background-Aware Motion-Guided Objects Discovery](http://arxiv.org/abs/2311.02633v1)
* [FATE: Feature-Agnostic Transformer-based Encoder for learning generalized embedding spaces in flow cytometry data](http://arxiv.org/abs/2311.03314v1)<br>:star:[code](https://github.com/lisaweijler/FATE)
* [Instruct Me More! Random Prompting for Visual In-Context Learning](http://arxiv.org/abs/2311.03648v1)<br>:star:[code](https://github.com/Jackieam/InMeMo)
* [Mini but Mighty: Finetuning ViTs with Mini Adapters](http://arxiv.org/abs/2311.03873v1)
* [Efficient Semantic Matching with Hypercolumn Correlation](http://arxiv.org/abs/2311.04336v1)
* [MixtureGrowth: Growing Neural Networks by Recombining Learned Parameters](http://arxiv.org/abs/2311.04251v1)<br>:star:[code](https://github.com/chaudatascience/mixturegrowth)
* [Layer-wise Auto-Weighting for Non-Stationary Test-Time Adaptation](http://arxiv.org/abs/2311.05858v1)
* [A Neural Height-Map Approach for the Binocular Photometric Stereo Problem](https://arxiv.org/abs/2311.05958)
* [CrashCar101: Procedural Generation for Damage Assessment](http://arxiv.org/abs/2311.06536v1)
* [Self-Annotated 3D Geometric Learning for Smeared Points Removal](http://arxiv.org/abs/2311.09029v1)<br>:star:[code](https://github.com/wangmiaowei/wacv2024_smearedremover.git)<br>:house:[project](https://wacv2024.thecvf.com/)
* [Few-shot Shape Recognition by Learning Deep Shape-aware Features](http://arxiv.org/abs/2312.01315v1)
* [Learning to Compose SuperWeights for Neural Parameter Allocation Search](http://arxiv.org/abs/2312.01274v1)
* [Learn to Unlearn for Deep Neural Networks: Minimizing Unlearning Interference with Gradient Projection](https://arxiv.org/abs/2312.04095)
* [Hybrid Sample Synthesis-based Debiasing of Classifier in Limited Data Setting](https://arxiv.org/abs/2312.08288)
* [Label Shift Estimation for Class-Imbalance Problem: A Bayesian Approach](https://openaccess.thecvf.com/content/WACV2024/papers/Ye_Label_Shift_Estimation_for_Class-Imbalance_Problem_A_Bayesian_Approach_WACV_2024_paper.pdf)


<a name="0"/>

## 2020 å¹´è®ºæ–‡åˆ†ç±»æ±‡æ€»æˆ³è¿™é‡Œ
â†˜ï¸[CVPR-2020-Papers](https://github.com/52CV/CVPR-2020-Papers) 
â†˜ï¸[ECCV-2020-Papers](https://github.com/52CV/ECCV-2020-Papers)

<a name="00"/>

## 2021 å¹´è®ºæ–‡åˆ†ç±»æ±‡æ€»æˆ³è¿™é‡Œ
â†˜ï¸[ICCV-2021-Papers](https://github.com/52CV/ICCV-2021-Papers)
â†˜ï¸[CVPR-2021-Papers](https://github.com/52CV/CVPR-2021-Papers)

<a name="000"/>

## 2022 å¹´è®ºæ–‡åˆ†ç±»æ±‡æ€»æˆ³è¿™é‡Œ
â†˜ï¸[CVPR-2022-Papers](https://github.com/52CV/CVPR-2022-Papers/blob/main/README.md)
â†˜ï¸[WACV-2022-Papers](https://github.com/52CV/WACV-2022-Papers)
â†˜ï¸[ECCV-2022-Papers](https://github.com/52CV/ECCV-2022-Papers/blob/main/README.md)

### æ‰«ç CVå›å¾®ä¿¡(æ³¨æ˜ï¼šCVPR)å…¥å¾®ä¿¡äº¤æµç¾¤ï¼š
![9475fa20fd5e95235d9fa23ae9587a2](https://user-images.githubusercontent.com/62801906/156720309-de92964f-a6da-464a-b21f-cfb270c13e27.png)