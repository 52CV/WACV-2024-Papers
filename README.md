# WACV-2024-Papers
![Alt text](96748913c73db498eb8249e43c245b8.jpg)
## 会议时间：2024年1月3-7日
## 会议网址：https://wacv2024.thecvf.com/

## 查看2023年综述文献点这里↘️[2023-CV-Surveys](https://github.com/52CV/CV-Surveys)

## 2024 年论文分类汇总戳这里
↘️[WACV-2024-Papers](https://github.com/52CV/WACV-2024-Papers)

## 2023 年论文分类汇总戳这里
↘️[CVPR-2023-Papers](https://github.com/52CV/CVPR-2023-Papers)
↘️[WACV-2023-Papers](https://github.com/52CV/WACV-2023-Papers)
↘️[ICCV-2023-Papers](https://github.com/52CV/ICCV-2023-Papers)

## [2022 年论文分类汇总戳这里](#000)
## [2021 年论文分类汇总戳这里](#00)
## [2020 年论文分类汇总戳这里](#0)


## 12月1-8日更新11篇，计146+11篇.
* [SICKLE: A Multi-Sensor Satellite Imagery Dataset Annotated with Multiple Key Cropping Parameters](http://arxiv.org/abs/2312.00069v1)
* [Generalization by Adaptation: Diffusion-Based Domain Extension for Domain-Generalized Semantic Segmentation](http://arxiv.org/abs/2312.01850v1)<br>:star:[code](https://github.com/JNiemeijer/DIDEX)
* [Multimodality-guided Image Style Transfer using Cross-modal GAN Inversion](http://arxiv.org/abs/2312.01671v1)<br>:star:[code](https://hywang66.github.io/mmist/)
* [Few-shot Shape Recognition by Learning Deep Shape-aware Features](http://arxiv.org/abs/2312.01315v1)
* [Learning to Compose SuperWeights for Neural Parameter Allocation Search](http://arxiv.org/abs/2312.01274v1)
* [Meta-Learned Attribute Self-Interaction Network for Continual and Generalized Zero-Shot Learning](http://arxiv.org/abs/2312.01167v1)
* [Token Fusion: Bridging the Gap between Token Pruning and Token Merging](http://arxiv.org/abs/2312.01026v1)
* [Efficient Expansion and Gradient Based Task Inference for Replay Free Incremental Learning](http://arxiv.org/abs/2312.01188v1)
* [You Can Run but not Hide: Improving Gait Recognition with Intrinsic Occlusion Type Awareness](http://arxiv.org/abs/2312.02290v1)
* [Learn to Unlearn for Deep Neural Networks: Minimizing Unlearning Interference with Gradient Projection](https://arxiv.org/abs/2312.04095)
* [Residual Graph Convolutional Network for Bird's-Eye-View Semantic Segmentation](https://arxiv.org/abs/2312.04044)

## 目录

|:cat:|:dog:|:tiger:|:wolf:|
|------|------|------|------|
|[1.其它(Other)](#1)|[2.SR(超分辨率)](#2)|[3.Image/Video Retrieval(图像/视频检索)](#3)|[4.Image/Video Caption(图像/视频字幕)](#4)|
|[5.Image/Video Composition(图像/视频压缩)](#5)|[6.Medical Image(医学图像处理)](#6)|[7.3D(三维重建\三维视觉)](#7)|[8.Face(人脸技术)](#8)|
|[9.Image Segmentation(图像分割)](#9)|[10.Object Detector(目标检测)](#10)|[11.Object Tracking(目标跟踪)](#11)|[12.UAV/RS/Satellite Image(无人机/遥感/卫星图像)](#12)|
|[13.Reid(人员重识别/步态识别/行人检测)](#13)|[14.OCR(文本检测识别)](#14)|[15.Video](#15)|[16.Action Detection(动作检测)](#16)|
|[17.Human Pose Estimation(人体姿态估计)](#17)|[18.GAN/生成](#18)|[19.SLAM/AR/VR/Robotics(增强/虚拟现实/机器人)](#19)|[20.VQA(视觉问答)](#20)|


## Computed Imaging(计算成像，如光学、几何、光场成像等)
* [On the Quantification of Image Reconstruction Uncertainty without Training Data](http://arxiv.org/abs/2311.09639v1)

## Neural Radiance Fields
* [Hyb-NeRF: A Multiresolution Hybrid Encoding for Neural Radiance Fields](https://arxiv.org/abs/2311.12490)

## Deepfake
* [Weakly-supervised deepfake localization in diffusion-generated images](http://arxiv.org/abs/2311.04584v1)

## Biometrics(生物特征识别)
* [Fingervein Verification using Convolutional Multi-Head Attention Network](http://arxiv.org/abs/2310.16808v1)

##
* [NITEC: Versatile Hand-Annotated Eye Contact Dataset for Ego-Vision Interaction](http://arxiv.org/abs/2311.04505v1)<br>:star:[code](https://github.com/thohemp/nitec)

## Style Transfer(风格迁移)
* [Multimodality-guided Image Style Transfer using Cross-modal GAN Inversion](http://arxiv.org/abs/2312.01671v1)<br>:star:[code](https://hywang66.github.io/mmist/)

## sound(语音)
* 声源定位
  * [Can CLIP Help Sound Source Localization?](http://arxiv.org/abs/2311.04066v1)
* 音频分离  
  * [LAVSS: Location-Guided Audio-Visual Spatial Audio Separation](https://arxiv.org/abs/2310.20446)

## Dataset(数据集)
* [SyntheWorld: A Large-Scale Synthetic Dataset for Land Cover Mapping and Building Change Detection](https://arxiv.org/abs/2309.01907)<br>:sunflower:[dataset](https://github.com/JTRNEO/SyntheWorld)
* [IndustReal: A Dataset for Procedure Step Recognition Handling Execution Errors in Egocentric Videos in an Industrial-Like Setting](http://arxiv.org/abs/2310.17323v1)<br>:star:[code](https://github.com/TimSchoonbeek/IndustReal)
* [SICKLE: A Multi-Sensor Satellite Imagery Dataset Annotated with Multiple Key Cropping Parameters](https://arxiv.org/abs/2312.00069)
* [SICKLE: A Multi-Sensor Satellite Imagery Dataset Annotated with Multiple Key Cropping Parameters](http://arxiv.org/abs/2312.00069v1)
* 基准
  * [ISAR: A Benchmark for Single- and Few-Shot Object Instance Segmentation and Re-Identification](http://arxiv.org/abs/2311.02734v1)
  * [ConeQuest: A Benchmark for Cone Segmentation on Mars](http://arxiv.org/abs/2311.08657v1)<br>:star:[code](https://github.com/kerner-lab/ConeQuest)

## NeRF
* [Fast Sun-aligned Outdoor Scene Relighting based on TensoRF](http://arxiv.org/abs/2311.03965v1)

## Vision Transformers
* [Open-NeRF: Towards Open Vocabulary NeRF Decomposition](http://arxiv.org/abs/2310.16383v1)
* [Limited Data, Unlimited Potential: A Study on ViTs Augmented by Masked Autoencoders](https://arxiv.org/abs/2310.20704)
* [GTP-ViT: Efficient Vision Transformers via Graph-based Token Propagation](http://arxiv.org/abs/2311.03035v1)<br>:star:[code](https://github.com/Ackesnal/GTP-ViT)
* [SBCFormer: Lightweight Network Capable of Full-size ImageNet Classification at 1 FPS on Single Board Computers](http://arxiv.org/abs/2311.03747v1)<br>:star:[code](https://github.com/xyongLu/SBCFormer)


## Dense Prediction(密集预测)
* [PolyMaX: General Dense Prediction with Mask Transformer](http://arxiv.org/abs/2311.05770v1)

## Visual Tampering Detection(视觉篡改检测)
* 包裹防伪检测
  * [TAMPAR: Visual Tampering Detection for Parcel Logistics in Postal Supply Chains](http://arxiv.org/abs/2311.03124v1)<br>:star:[code](https://a-nau.github.io/tampar)

## visual industrial inspection(工业检测)
* [Attention Modules Improve Image-Level Anomaly Detection for Industrial Inspection: A DifferNet Case Study](http://arxiv.org/abs/2311.02747v1)


## Anomaly Detection
* [Cheating Depth: Enhancing 3D Surface Anomaly Detection via Depth Simulation](http://arxiv.org/abs/2311.01117v1)


## Image Fusion(图像融合)
* [Bridging the Gap between Multi-focus and Multi-modal: A Focused Integration Framework for Multi-modal Image Fusion](http://arxiv.org/abs/2311.01886v1)<br>:star:[code](https://github.com/ixilai/MFIF-MMIF)

## Image Classification(图像分类)
* 小样本分类
  * [Domain Aligned CLIP for Few-shot Classification](http://arxiv.org/abs/2311.09191v1)

## Image Progress(低层图像处理、质量评价)
* 图像矫正
  * [4K-Resolution Photo Exposure Correction at 125 FPS with ~8K Parameters](http://arxiv.org/abs/2311.08759v1)<br>:star:[code](https://github.com/Zhou-Yijie/MSLTNet)


## Semi-supervised learning
* 无监督学习
  * [United We Stand, Divided We Fall: UnityGraph for Unsupervised Procedure Learning from Videos](http://arxiv.org/abs/2311.03550v1)
* 半监督学习
  * [SequenceMatch: Revisiting the design of weak-strong augmentations for Semi-supervised learning](https://arxiv.org/abs/2310.15787)<br>:star:[code](https://github.com/beandkay/SequenceMatch)
  * [Debiasing, calibrating, and improving Semi-supervised Learning performance via simple Ensemble Projector](https://arxiv.org/abs/2310.15764)<br>:star:[code](https://github.com/beandkay/EPASS)
* 自监督学习
  * [CycleCL: Self-supervised Learning for Periodic Videos](http://arxiv.org/abs/2311.03402v1)
  * [Self-Supervised Learning for Visual Relationship Detection through Masked Bounding Box Reconstruction](http://arxiv.org/abs/2311.04834v1)<br>:star:[code](https://github.com/deeplab-ai/SelfSupervisedVRD)

## Few/Zero-Shot Learning/Domain Generalization/Adaptation(小/零样本/域泛化/域适应)
* 零样本学习
  * [GIPCOL: Graph-Injected Soft Prompting for Compositional Zero-Shot Learning](http://arxiv.org/abs/2311.05729v1)
  * [Meta-Learned Attribute Self-Interaction Network for Continual and Generalized Zero-Shot Learning](http://arxiv.org/abs/2312.01167v1)
* 小样本学习
  * [Hyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin](https://arxiv.org/abs/2309.10013)
* DG
  * [Learning Class and Domain Augmentations for Single-Source Open-Domain Generalization](http://arxiv.org/abs/2311.02599v1)
* DA
  * [Gradual Source Domain Expansion for Unsupervised Domain Adaptation](http://arxiv.org/abs/2311.09599v1)
  * [Bridging Generalization Gaps in High Content Imaging Through Online Self-Supervised Domain Adaptation](https://arxiv.org/abs/2311.12623)<br>:star:[code](https://github.com/cfredinh/coda)
  * [GLAD: Global-Local View Alignment and Background Debiasing for Unsupervised Video Domain Adaptation with Large Domain Gap](https://arxiv.org/abs/2311.12467)<br>:star:[code](https://github.com/KHU-VLL/GLAD)
  * [Aligning Non-Causal Factors for Transformer-Based Source-Free Domain Adaptation](https://arxiv.org/abs/2311.16294)<br>:house:[project](https://val.cds.iisc.ac.in/C-SFTrans/)

## Machine Learning(机器学习)
* 持续学习/增量学习
  * [Efficient Expansion and Gradient Based Task Inference for Replay Free Incremental Learning](http://arxiv.org/abs/2312.01188v1)
  * 类增量
    * [Wakening Past Concepts without Past Data: Class-Incremental Learning from Online Placebos](http://arxiv.org/abs/2310.16115v1)<br>:star:[code](https://github.com/yaoyao-liu/online-placebos)
    * [Robust Feature Learning and Global Variance-Driven Classifier Alignment for Long-Tail Class Incremental Learning](http://arxiv.org/abs/2311.01227v1)
  * CL
    * [Plasticity-Optimized Complementary Networks for Unsupervised Continual Learning](https://arxiv.org/abs/2309.06086)
* 度量学习
  * [ProcSim: Proxy-based Confidence for Robust Similarity Learning](http://arxiv.org/abs/2311.00668v1)
* 对抗学习
  * [Army of Thieves: Enhancing Black-Box Model Extraction via Ensemble based sample selection](http://arxiv.org/abs/2311.04588v1)


## Model Compression/Knowledge Distillation/Pruning(模型压缩/知识蒸馏/剪枝)
* 量化
  * [Reducing the Side-Effects of Oscillations in Training of Quantized YOLO Networks](http://arxiv.org/abs/2311.05109v1)
  * [Evidential Uncertainty Quantification: A Variance-Based Perspective](https://arxiv.org/abs/2311.11367)
* 剪枝
  * [Token Fusion: Bridging the Gap between Token Pruning and Token Merging](http://arxiv.org/abs/2312.01026v1)

## NAS
* [FLORA: Fine-grained Low-Rank Architecture Search for Vision Transformer](http://arxiv.org/abs/2311.03912v1)<br>:star:[code](https://github.com/shadowpa0327/FLORA)

## Optical Flow Estimation(光流估计)
* [Detection Defenses: An Empty Promise against Adversarial Patch Attacks on Optical Flow](http://arxiv.org/abs/2310.17403v1)<br>:star:[code](https://github.com/cv-stuttgart/DetectionDefenses)
* [CCMR: High Resolution Optical Flow Estimation via Coarse-to-Fine Context-Guided Motion Reasoning](http://arxiv.org/abs/2311.02661v1)<br>:star:[code](https://github.com/cv-stuttgart)

## Multimodal(多模态)
* [Dynamic Multimodal Information Bottleneck for Multimodality Classification](http://arxiv.org/abs/2311.01066v1)<br>:star:[code](https://github.com/BII-wushuang/DMIB)
* [Enhancing Multimodal Compositional Reasoning of Visual Language Models with Generative Negative Mining](https://arxiv.org/abs/2311.03964)<br>:star:[code](https://github.com/ugorsahin/Generative-Negative-Mining)
* [OmniVec: Learning robust representations with cross modal sharing](http://arxiv.org/abs/2311.05709v1)

## Object Pose Estimation(物体姿态估计)
* 6-DoF
  * [Real-time 6-DoF Pose Estimation by an Event-based Camera using Active LED Markers](http://arxiv.org/abs/2310.16618v1)

## Lage Language Models
## Vision-Language(视觉语言)
* [Towards Addressing the Misalignment of Object Proposal Evaluation for Vision-Language Tasks via Semantic Grounding](https://arxiv.org/abs/2309.00215)

<a name="20"/>

## 20.Visual Answer Questions(视觉问答)
* 视觉对话
  * [VD-GR: Boosting Visual Dialog with Cascaded Spatial-Temporal Multi-Modal GRaphs](http://arxiv.org/abs/2310.16590v1)

<a name="19"/>

## 19.SLAM/Augmented Reality/Virtual Reality/Robotics(增强/虚拟现实/机器人)
* 虚拟试穿
  * [A Generative Multi-Resolution Pyramid and Normal-Conditioning 3D Cloth Draping](http://arxiv.org/abs/2311.02700v1)
  * [GC-VTON: Predicting Globally Consistent and Occlusion Aware Local Flows with Neighborhood Integrity Preservation for Virtual Try-on](http://arxiv.org/abs/2311.04932v1)
* 虚拟化身
  * [CVTHead: One-shot Controllable Head Avatar with Vertex-feature Transformer](http://arxiv.org/abs/2311.06443v1)

<a name="18"/>

## 18.GAN/生成
* GAN
  * [PlantPlotGAN: A Physics-Informed Generative Adversarial Network for Plant Disease Prediction](https://arxiv.org/abs/2310.18268)
* 扩散
  * [Expanding Expressiveness of Diffusion Models with Limited Data via Self-Distillation based Fine-Tuning](http://arxiv.org/abs/2311.01018v1)
* 图像生成
  * [Improving the Effectiveness of Deep Generative Data](http://arxiv.org/abs/2311.03959v1)
* 图像合成
  * [Painterly Image Harmonization via Adversarial Residual Learning](http://arxiv.org/abs/2311.08646v1)

<a name="17"/>

## 17.Human Pose Estimation
* [Active Transfer Learning for Efficient Video-Specific Human Pose Estimation](http://arxiv.org/abs/2311.05041v1)<br>:star:[code](https://github.com/ImIntheMiddle/VATL4Pose-WACV2024)
* 手势
  * 手语翻译
    * [Fingerspelling PoseNet: Enhancing Fingerspelling Translation with Pose-Based Transformer Models](https://arxiv.org/abs/2311.12128)<br>:star:[code](https://github.com/pooyafayyaz/Fingerspelling-PoseNet)

<a name="16"/>

## 16.Action Detection(动作检测)
* 小样本动作检测
  * [Semantic-aware Video Representation for Few-shot Action Recognition](http://arxiv.org/abs/2311.06218v1)
* 时序动作分割
  * [OTAS: Unsupervised Boundary Detection for Object-Centric Temporal Action Segmentation](https://arxiv.org/abs/2309.06276)
* 动作检测
  * [A Hybrid Graph Network for Complex Activity Detection in Video](http://arxiv.org/abs/2310.17493v1)
* 动作预测
  * [Object-centric Video Representation for Long-term Action Anticipation](http://arxiv.org/abs/2311.00180v1)<br>:star:[code](https://github.com/brown-palm/ObjectPrompt)
* 动作质量评估
  * [PECoP: Parameter Efficient Continual Pretraining for Action Quality Assessment](http://arxiv.org/abs/2311.07603v1)<br>:star:[code](https://github.com/Plrbear/PECoP)

<a name="15"/>

## 15.Video
* 视频分割
  * [Correlation-aware active learning for surgery video segmentation](http://arxiv.org/abs/2311.08811v1)
* 视频识别
  * [Automated Sperm Assessment Framework and Neural Network Specialized for Sperm Video Recognition](http://arxiv.org/abs/2311.05927v1)
* 视频时刻检索
  * [Zero-Shot Video Moment Retrieval from Frozen Vision-Language Models](https://arxiv.org/abs/2309.00661)
* VAD
  * [A Coarse-to-Fine Pseudo-Labeling (C2FPL) Framework for Unsupervised Video Anomaly Detection](http://arxiv.org/abs/2310.17650v1)

<a name="14"/>

## 14.OCR(文本检测识别)
* [DTrOCR: Decoder-only Transformer for Optical Character Recognition](https://arxiv.org/abs/2308.15996)
* [On Manipulating Scene Text in the Wild with Diffusion Models](http://arxiv.org/abs/2311.00734v1)
* [DECDM: Document Enhancement using Cycle-Consistent Diffusion Models](http://arxiv.org/abs/2311.09625v1)
* Text Spotting
  * [Harnessing the Power of Multi-Lingual Datasets for Pre-training: Towards Enhancing Text Spotting Performance](https://arxiv.org/abs/2310.00917)
  * [Hierarchical Text Spotter for Joint Text Spotting and Layout Analysis](https://arxiv.org/abs/2310.17674)

<a name="13"/>

## 13.Reid(人员重识别/步态识别/行人检测)
* Reid
  * [HashReID: Dynamic Network with Binary Codes for Efficient Person Re-identification](https://arxiv.org/abs/2308.11900)
  * [Mitigate Domain Shift by Primary-Auxiliary Objectives Association for Generalizing Person ReID](https://arxiv.org/abs/2310.15913)
* 行人识别
  * [ShARc: Shape and Appearance Recognition for Person Identification In-the-wild](https://arxiv.org/abs/2310.15946)
* 行人搜索
  * [DDAM-PS: Diligent Domain Adaptive Mixer for Person Search](https://arxiv.org/abs/2310.20706)<br>:star:[code](https://github.com/mustansarfiaz/DDAM-PS)
* 人群计数
  * 基于红外的人群计数
    * [Evaluating Supervision Levels Trade-Offs for Infrared-Based People Counting](https://arxiv.org/abs/2311.11974)<br>:star:[code](https://github.com/tortueTortue/IRPeopleCounting)
* 步态识别
  * [You Can Run but not Hide: Improving Gait Recognition with Intrinsic Occlusion Type Awareness](http://arxiv.org/abs/2312.02290v1)

<a name="12"/>

## 12.UAV/Remote Sensing/Satellite Image(无人机/遥感/卫星图像)
* 树冠检测
  * [ShadowSense: Unsupervised Domain Adaptation and Feature Fusion for Shadow-Agnostic Tree Crown Detection from RGB-Thermal Drone Imagery](http://arxiv.org/abs/2310.16212v1)<br>:star:[code](https://github.com/rudrakshkapil/ShadowSense)<br>:star:[code](https://github.com/rudrakshkapil/ShadowSense)
* 变化检测
  * [Effective Restoration of Source Knowledge in Continual Test Time Adaptation](http://arxiv.org/abs/2311.04991v1)
  * [SeaDSC: A video-based unsupervised method for dynamic scene change detection in unmanned surface vehicles](https://arxiv.org/abs/2311.11580)

<a name="11"/>

## 11.Object Tracking(目标跟踪)
* [Separable Self and Mixed Attention Transformers for Efficient Object Tracking](https://arxiv.org/abs/2309.03979)<br>:star:[code](https://github.com/goutamyg/SMAT)
* MOT
  * [Contrastive Learning for Multi-Object Tracking with Transformers](http://arxiv.org/abs/2311.08043v1)

<a name="10"/>

## 10.Object Detector(目标检测)
* [MultIOD: Rehearsal-free Multihead Incremental Object Detector](https://arxiv.org/abs/2309.05334)
* [Towards Few-Annotation Learning for Object Detection: Are Transformer-based Models More Efficient ?](https://arxiv.org/abs/2310.19936)
* [TPSeNCE: Towards Artifact-Free Realistic Rain Generation for Deraining and Object Detection in Rain](http://arxiv.org/abs/2311.00660v1)<br>:star:[code](https://github.com/ShenZheng2000/TPSeNCE)
* 协同显著目标检测
  * [Unsupervised and semi-supervised co-salient object detection via segmentation frequency statistics](http://arxiv.org/abs/2311.06654v1)
* 开放词汇目标检测
  * [LP-OVOD: Open-Vocabulary Object Detection by Linear Probing](http://arxiv.org/abs/2310.17109v1)<br>:star:[code](https://github.com/VinAIResearch/LP-OVOD)
* 小目标检测
  * [RPCANet: Deep Unfolding RPCA Based Infrared Small Target Detection](http://arxiv.org/abs/2311.00917v1)
  * [S$^3$AD: Semi-supervised Small Apple Detection in Orchard Environments](http://arxiv.org/abs/2311.05029v1)<br>:house:[project](http://www.inf.uni-hamburg.de/mad)

<a name="9"/>

## 9.Image Segmentation(图像分割)
* [Robust Source-Free Domain Adaptation for Fundus Image Segmentation](http://arxiv.org/abs/2310.16665v1)<br>:star:[code](https://github.com/LinGrayy/PLPB)
* 语义分割
  * [Unsupervised Domain Adaptation for Semantic Segmentation with Pseudo Label Self-Refinement](http://arxiv.org/abs/2310.16979v1)
  * [Residual Graph Convolutional Network for Bird's-Eye-View Semantic Segmentation](https://arxiv.org/abs/2312.04044)
  * 3D语义分割  
    * [2D Feature Distillation for Weakly- and Semi-Supervised 3D Semantic Segmentation](https://arxiv.org/abs/2311.15605)
  * 细粒度语义分割  
    * [CPSeg: Finer-grained Image Semantic Segmentation via Chain-of-Thought Language Prompting](http://arxiv.org/abs/2310.16069v1)
  * 弱监督语义分割 
    * [Small Objects Matters in Weakly-supervised Semantic Segmentation](https://arxiv.org/abs/2309.14117)
  * 域适应语义分割
     * [Generalization by Adaptation: Diffusion-Based Domain Extension for Domain-Generalized Semantic Segmentation](http://arxiv.org/abs/2312.01850v1)<br>:star:[code](https://github.com/JNiemeijer/DIDEX)
* 场景理解
  * [TSP-Transformer: Task-Specific Prompts Boosted Transformer for Holistic Scene Understanding](http://arxiv.org/abs/2311.03427v1)<br>:star:[code](https://github.com/tb2-sy/TSP-Transformer)
  * [Rethink Cross-Modal Fusion in Weakly-Supervised Audio-Visual Video Parsing](http://arxiv.org/abs/2311.08151v1)
* 场景分割
  * [IDD-AW: A Benchmark for Safe and Robust Segmentation of Drive Scenes in Unstructured Traffic and Adverse Weather](https://arxiv.org/abs/2311.14459)
* 语义场景分割
  * [U3DS$^3$: Unsupervised 3D Semantic Scene Segmentation](http://arxiv.org/abs/2311.06018v1)
* VOS
  * [Learning the What and How of Annotation in Video Object Segmentation](http://arxiv.org/abs/2311.04414v1)


<a name="8"/>

## 8.Face(人脸技术)
* [ProS: Facial Omni-Representation Learning via Prototype-based Self-Distillation](http://arxiv.org/abs/2311.01929v1)
* [Improving Fairness using Vision-Language Driven Image Augmentation](http://arxiv.org/abs/2311.01573v1)<br>:star:[code](https://github.com/Moreno98/Vision-Language-Bias-Control)
* FPAD
  * [Face Presentation Attack Detection by Excavating Causal Clues and Adapting Embedding Statistics](https://arxiv.org/abs/2308.14551)<br>:star:[code](https://github.com/meilfang/CF-PAD)
* 说话头
  * [LaughTalk: Expressive 3D Talking Head Generation with Laughter](http://arxiv.org/abs/2311.00994v1)
  * [3D-Aware Talking-Head Video Motion Transfer](http://arxiv.org/abs/2311.02549v1)
  * [THInImg: Cross-modal Steganography for Presenting Talking Heads in Images](https://arxiv.org/abs/2311.17177)
* 年龄分类
  * [P-Age: Pexels Dataset for Robust Spatio-Temporal Apparent Age Classification](http://arxiv.org/abs/2311.02432v1)
* 人脸识别
  * [Bias and Diversity in Synthetic-based Face Recognition](http://arxiv.org/abs/2311.03970v1)
* 人脸风格迁移
  * [3D Face Style Transfer with a Hybrid Solution of NeRF and Mesh Rasterization](https://arxiv.org/abs/2311.13168)

<a name="7"/>

## 7.3D(三维重建\三维视觉)
* 深度估计
  * [Semi-Supervised Semantic Depth Estimation using Symbiotic Transformer and NearFarMix Augmentation](https://arxiv.org/abs/2308.14400)
  * [Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation](http://arxiv.org/abs/2311.01034v1)
  * [Continual Learning of Unsupervised Monocular Depth from Videos](http://arxiv.org/abs/2311.02393v1)
  * [MonoProb: Self-Supervised Monocular Depth Estimation with Interpretable Uncertainty](http://arxiv.org/abs/2311.06137v1)<br>:star:[code](https://github.com/CEA-LIST/MonoProb)
* 三维重建
  * [Toward Planet-Wide Traffic Camera Calibration](http://arxiv.org/abs/2311.04243v1)<br>:house:[project](https://www.khiemvuong.com/OpenTrafficCam3D)
  * [Registered and Segmented Deformable Object Reconstruction from a Single View Point Cloud](http://arxiv.org/abs/2311.07357v1)

<a name="6"/>

## 6.Medical Image(医学图像处理)
* 3D
  * [Adaptive Latent Diffusion Model for 3D Medical Image to Image Translation: Multi-modal Magnetic Resonance Imaging Study](http://arxiv.org/abs/2311.00265v1)
* 报告生成
  * [Complex Organ Mask Guided Radiology Report Generation](http://arxiv.org/abs/2311.02329v1)
* 医学图像分割
  * [G-CASCADE: Efficient Cascaded Graph Convolutional Decoding for 2D Medical Image Segmentation](http://arxiv.org/abs/2310.16175v1)
  * [SynergyNet: Bridging the Gap between Discrete and Continuous Representations for Precise Medical Image Segmentation](https://arxiv.org/abs/2310.17764)
  * [MIST: Medical Image Segmentation Transformer with Convolutional Attention Mixing (CAM) Decoder](https://arxiv.org/abs/2310.19898)
* 医学图像分类
  * [PHG-Net: Persistent Homology Guided Medical Image Classification](https://arxiv.org/abs/2311.17243)<br>:star:[code](https://github.com/yaoppeng/TopoClassification)
* 糖尿病视网膜分类
  * [Generalizing to Unseen Domains in Diabetic Retinopathy Classification](http://arxiv.org/abs/2310.17255v1)

<a name="5"/>

## 5.Image/Video Composition(图像/视频压缩)
* [Differentiable JPEG: The Devil is in the Details](https://arxiv.org/abs/2309.06978)<br>:star:[code](https://github.com/necla-ml/Diff-JPEG)
* VC
  * [Blurry Video Compression: A Trade-off between Visual Enhancement and Data Compression](http://arxiv.org/abs/2311.04430v1)

<a name="4"/>

## 4.Image/Video Caption(图像/视频字幕)
* [Augment the Pairs: Semantics-Preserving Image-Caption Pair Augmentation for Grounding-Based Vision and Language Models](http://arxiv.org/abs/2311.02536v1)<br>:star:[code](https://github.com/amzn/augment-the-pairs-wacv2024)

<a name="3"/>

## 3.Image/Video Retrieval(图像/视频检索)
* 文本-穿搭检索(时尚推荐)
  * [Lost Your Style? Navigating with Semantic-Level Approach for Text-to-Outfit Retrieval](http://arxiv.org/abs/2311.02122v1)

<a name="2"/>

## 2.Super-Resolution(超分辨率)
* [Scene Text Image Super-resolution based on Text-conditional Diffusion Models](http://arxiv.org/abs/2311.09759v1)
* VSR
  * [Scale-Adaptive Feature Aggregation for Efficient Space-Time Video Super-Resolution](http://arxiv.org/abs/2310.17294v1)

<a name="1"/>

## 1.其它
* [REALM: Robust Entropy Adaptive Loss Minimization for Improved Single-Sample Test-Time Adaptation](https://arxiv.org/abs/2309.03964)
* [Occlusion Sensitivity Analysis with Augmentation Subspace Perturbation in Deep Feature Space](https://arxiv.org/abs/2311.15022)
* [SENetV2: Aggregated dense layer for channelwise and global representations](https://arxiv.org/abs/2311.10807)
* [RecycleNet: Latent Feature Recycling Leads to Iterative Decision Refinement](https://arxiv.org/abs/2309.07513)
* [Learning Low-Rank Latent Spaces with Simple Deterministic Autoencoder: Theoretical and Empirical Insights](http://arxiv.org/abs/2310.16194v1)
* [Learning Robust Deep Visual Representations from EEG Brain Recordings](http://arxiv.org/abs/2310.16532v1)
* [MACP: Efficient Model Adaptation for Cooperative Perception](http://arxiv.org/abs/2310.16870v1)<br>:star:[code](https://github.com/PurdueDigitalTwin/MACP)
* [The Background Also Matters: Background-Aware Motion-Guided Objects Discovery](http://arxiv.org/abs/2311.02633v1)
* [FATE: Feature-Agnostic Transformer-based Encoder for learning generalized embedding spaces in flow cytometry data](http://arxiv.org/abs/2311.03314v1)<br>:star:[code](https://github.com/lisaweijler/FATE)
* [Instruct Me More! Random Prompting for Visual In-Context Learning](http://arxiv.org/abs/2311.03648v1)<br>:star:[code](https://github.com/Jackieam/InMeMo)
* [Mini but Mighty: Finetuning ViTs with Mini Adapters](http://arxiv.org/abs/2311.03873v1)
* [Efficient Semantic Matching with Hypercolumn Correlation](http://arxiv.org/abs/2311.04336v1)
* [MixtureGrowth: Growing Neural Networks by Recombining Learned Parameters](http://arxiv.org/abs/2311.04251v1)<br>:star:[code](https://github.com/chaudatascience/mixturegrowth)
* [Layer-wise Auto-Weighting for Non-Stationary Test-Time Adaptation](http://arxiv.org/abs/2311.05858v1)
* [A Neural Height-Map Approach for the Binocular Photometric Stereo Problem](https://arxiv.org/abs/2311.05958)
* [CrashCar101: Procedural Generation for Damage Assessment](http://arxiv.org/abs/2311.06536v1)
* [Self-Annotated 3D Geometric Learning for Smeared Points Removal](http://arxiv.org/abs/2311.09029v1)<br>:star:[code](https://github.com/wangmiaowei/wacv2024_smearedremover.git)<br>:house:[project](https://wacv2024.thecvf.com/)
* [Few-shot Shape Recognition by Learning Deep Shape-aware Features](http://arxiv.org/abs/2312.01315v1)
* [Learning to Compose SuperWeights for Neural Parameter Allocation Search](http://arxiv.org/abs/2312.01274v1)
* [Learn to Unlearn for Deep Neural Networks: Minimizing Unlearning Interference with Gradient Projection](https://arxiv.org/abs/2312.04095)


<a name="0"/>

## 2020 年论文分类汇总戳这里
↘️[CVPR-2020-Papers](https://github.com/52CV/CVPR-2020-Papers) 
↘️[ECCV-2020-Papers](https://github.com/52CV/ECCV-2020-Papers)

<a name="00"/>

## 2021 年论文分类汇总戳这里
↘️[ICCV-2021-Papers](https://github.com/52CV/ICCV-2021-Papers)
↘️[CVPR-2021-Papers](https://github.com/52CV/CVPR-2021-Papers)

<a name="000"/>

## 2022 年论文分类汇总戳这里
↘️[CVPR-2022-Papers](https://github.com/52CV/CVPR-2022-Papers/blob/main/README.md)
↘️[WACV-2022-Papers](https://github.com/52CV/WACV-2022-Papers)
↘️[ECCV-2022-Papers](https://github.com/52CV/ECCV-2022-Papers/blob/main/README.md)

### 扫码CV君微信(注明：CVPR)入微信交流群：
![9475fa20fd5e95235d9fa23ae9587a2](https://user-images.githubusercontent.com/62801906/156720309-de92964f-a6da-464a-b21f-cfb270c13e27.png)